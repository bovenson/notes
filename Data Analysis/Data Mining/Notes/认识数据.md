---
title: 认识数据
tags: 数据挖掘, 认识数据
---

[TOC]

# 数据对象与属性类型

## 1. 1数据对象与属性类型

### 1.1.1 什么是属性

**属性** 是一个数据字段，表示数据对象的一个特征。

属性可以是：

- 标称的
- 二元的
- 序数的
- 数值的

### 1.1.2 标称属性

**标称属性**的值是一些符号或事物的_名称_。

### 1.1.3 二元属性

**二元属性** 是一种标称属性，只有两个类别或状态：0或1。

如果两种状态对应 true 和 false 的话，二元属性又称为**布尔属性**。

### 1.1.4 序数属性

**序数属性** 是一种属性，其可能的值之间具有有意义的序或秩评定，但是相继值之间的查是未知的。如：大、中、小。

序数属性的中心趋势，可以用它的众数和中位数表示。但不能定义均值。

### 1.1.5 数值属性

**数值属性** 是定量的，即它是可度量的量，用整数或实数值表示。

分为：

- 区间标度属性
- 比率标度属性

可以计算它们的均值、中位数、众数以及值之间的差。

### 1.1.6 离散属性与连续属性

**离散属性** 具有有限或无限可数个数。如果数据不是离散的，则它是**连续的**。

## 1.2 数据的基本统计描述

对于成功的数据预处理而言，把握数据的全貌是至关重要的。基本统计描述可以用来识别数据的性质，凸显哪些数据值应该视为噪声或离群点。

三类基本统计描述：

- 中心趋势：它度量数据分布的中部或中心。直观地说，给定一个属性，它的值大部分落在何处？

  - 均值
  - 中位数
  - 众数
  - 中列数

- 数据的散布：即数据如何分散？数据散布的最常见度量是数据的：

  - 极差
  - 四分位数
  - 四分位数极差
  - 五数概括
  - 盒图
  - 方差
  - 标准差

  对于识别离群点，这些度量是有用的

- 可视化审视数据

  - 条图
  - 饼图
  - 线图
  - 分位数图
  - 分位数-分位数图
  - 直方图
  - 散点图

### 1.2.1 中心趋势：均值、中位数、众数

#### 均值（mean）

$\bar{x} = \frac{\sum \limits _{i=1} \limits ^{N} x_i}{N} = \frac{x_1 + x_2 + … + x_N}{N}$

均值对极端值很敏感。可以使用截尾均值（丢弃高低极端值后的均值）。

##### 程序实现

```python
import pandas as pd

# 加载数据
train_df = pd.read_csv('./data/train.csv')

# 计算所有数值均值
train_df.mean()

# 计算某一列均值
train_df['Age'].mean()
```

[查看详细输出](../Jupyter/mean.ipynb)

**加权算术平均值** 或 **加权平均**

$\bar{x} = \frac{\sum \limits_{i=1} \limits^{N} w_i x_i}{\sum \limits_{i=1} \limits^{N}w_i} = \frac{w_1x_1+w_2x_2 + … + w_Nx_N}{w_1+w_2+…+w_N}$

#### 中位数（median）

对于倾斜（非对称）数据，数据中心的更好度量是 **中位数**。中位数是有序数据值的中间值。它是把较高的一半和较低的一半分开。

当观测数据很大时，中位数的计算开销很大。我们可以很容易地计算中位数近似值，令包含中位数频率的区间为中位数区间，用插值计算这个数据集的中位数的近似值：

$median = L_1 + (\frac{N/2 - (\sum freq)_l}{freq_{median}})width$

$L_1$ 是中位数区间的下界， $N$ 是整个数据集中值得个数， $(\sum freq)_l$ 是低于中位数区间的所有区间的频率和，$freq_{median}$ 是中位数区间的频率，$width$ 是中位数区间的宽度。

##### 程序实现

```python
import pandas as pd
import numpy as np
# 读取数据
train = pd.read_csv('./data/train.csv')

# 所有数值属性的中位数
train.median()

# Age 属性的中位数
train['Age'].median()
```

[查看详细输出](../Jupyter/show/median.ipynb)

#### 众数（mode）

众数是一种数据中心趋势度量。数据集的**众数（mode）**是集合中出现最频繁的值。

数据集可以使：

- 单峰的
- 多峰的（双峰、三峰...）
- 没有众数的

##### 程序实现

```python
import pandas as pd
import numpy as np
# 读取数据
train = pd.read_csv('./data/train.csv')

# Age 属性的众数
train['Age'].mode()

# 对非数值属性计算众数
train['Sex'].mode()
```

[查看详细输出](../Jupyter/mode.ipynb)

对于适度倾斜（非对称）的单峰数值数据，我们有下面的经验关系：

$mean - mode \approx 3 * (mean - median)$ 

这意味着，如果均值和中位数已知，则适度倾斜的单峰频率曲线的众数容易近似计算。

#### 中列数（midrange）

中列数是数据集的最大和最小值得平均值。

##### 程序实现

```python
import pandas as pd
import numpy as np
# 读取数据
train = pd.read_csv('./data/train.csv')

# 计算中列数
(train['Age'].max() + train['Age'].min()) / 2
```

### 1.2.2 度量数据散布：极差、四分位数、方差、标准差和四分位极差

#### 极差（range）

最大值与最小值之差

#### 分位数（quantile）

是取自数据分布的每隔一段时间上的点，把数据划分成基本上大小相等的连贯集合。

#### 四分位数（quartile）

把数据分布划分成4个相等的部分，使得每部分表示数据分布的四分之一，通常称它们为四分位数。

#### 四分位数极差（IQR）

$IQR = Q_3 - Q_1$

$Q_i$ : 第 $i$ 个四分位数。

#### 五数概括（five-number summary）

分布的五数概括由中位数($Q_2$)、四分位数 $Q_1$ 和 $Q_3$ 、最小和最大观测值组成，按次序 $Minimum$、$Q_1$、$Median$ 、$Q_3$ 、 $Maximum$ 写出。

#### 盒图（boxplot）

盒图是一种流行的分布的直观表示。盒图体现了五数概括：

- 盒的端点一般在四分位数上，使得盒的长度是四分位数极差 $IQR$
- 中位数用盒内的线标记
- 盒外的两条线（称作胡须）延伸到最小和最大观测值

盒图可以用来比较若干个可比较的数据集。

#### 方差（variance）和标准差（standard deviation）

方差和标准差都是数据散布的度量，它们指出数据分布的散布程度。

低标准差意味着数据观测趋向于非常靠近均值，而高标准差表示数据散布在一个大的值域中。

数据属性 X 的 N 个观测值 $x_1, x_2, …, x_N$ 的方差是：

$\sigma ^2 = \frac{1}{N} \sum \limits_{i=1} \limits^{N} (x_i - \bar{x}) ^2 = (\frac{1}{N} \sum \limits_{i=1} \limits^{N} x_i^2)^2 - \bar{x}^2$

标准差 $\sigma $ 是方差 $\sigma^2$ 的平方根。

作为发散性的度量，标准差 $\sigma$ 的性质是：

- $\sigma$ 度量关于均值的发散，仅当选择均值作为中心度量时使用
- 仅当不存在发散时，即当所有的观测值都具有相同值时，$\sigma = 0$ ；否则，$\sigma > 0$

#### 程序实现

```python
# coding: utf-8
# In[1]:
import pandas as pd
import matplotlib.pyplot as plt 
get_ipython().run_line_magic('matplotlib', 'inline')


# In[2]:
# 加载数据集
train = pd.read_csv('./data/train.csv')


# In[3]:
train.head(5)


# In[4]:
age = train['Age']


# In[5]:
# 极差
d_range = age.max() - age.min()
print(d_range)


# In[6]:
# 四分位数
quartile = age.quantile([.25, .5, .75])
print(quartile)


# In[7]:
# 四分位数极差
quartile = quartile.values
IQR = quartile[2] - quartile[0]
print(IQR)


# In[9]:
# 五数概括
q1 = quartile[0]
q3 = quartile[2]
minimum = age.min()
maxinum = age.max()
median = quartile[1]
print(minimum, q1, median, q3, maxinum)

# In[10]:
# 绘制盒图
# 年龄数据切分
ages = [age.values[i*200: (i+1)*200] for i in range(4)]

# 绘制盒图
age_df = pd.DataFrame({
    'part 1': ages[0],
    'part 2': ages[1],
    'part 3': ages[2],
    'part 4': ages[3],
})

age_df.boxplot()
plt.show()

# In[11]:
# 计算方差
age.var()

# In[12]:
# 计算标准差
age.std()
```

[查看详细输出](../Jupyter/数据散布.ipynb)

### 1.2.3 数据的基本统计描述的图形显示

#### 分位数图（quantile plot）

分位数图是一种观察单变量数据分布的简单有效方法。

#### 分位数-分位数图（quantile-quantile plot）

分位数-分位数图，或 **q-q图** 对着另一个对应的分位数，绘制一个单变量分布的分位数。它是一种强有力的可视化工具，使得用户可以观察从一个分布到另一个分布有漂移。

#### 直方图（histogram）

**直方图** 或 **频率直方图** 是一种概括给定属性 X 的分布的图形方法。

#### 散点图（scatter plot）

**散点图** 是确定两个数值之间看上去是否存在联系、模式或趋势的最有效的图形方法之一。

散点图是一种观察双变量数据的有用的方法，用于观察点簇和离群点，或考察相关联系的可能性。

两个属性 X 和 Y，如果一个属性蕴含另一个，则它们是相关的。

#### 程序实现

```python
# coding: utf-8
# In[1]:
import pandas as pd
import matplotlib.pyplot as plt 
get_ipython().run_line_magic('matplotlib', 'inline')
import scipy.stats as stats
import pylab
import numpy as np

# In[2]:
# 加载数据集
train = pd.read_csv('./data/train.csv')

# In[3]:
train.head(5)

# In[4]:
age = train['Age']

# In[21]:
# 画 q-q 图
stats.probplot(age.values, dist='norm', plot=pylab)
pylab.show()

# In[18]:
datas = np.random.normal(loc=20, scale=5, size=500)
stats.probplot(datas, dist='norm', plot=pylab)
pylab.show()

# In[15]:
stats.probplot(train['Fare'], dist='norm', plot=pylab)
pylab.show()

# In[20]:
stats.probplot(train['SibSp'], dist='norm', plot=pylab)
pylab.show()

# In[27]:
# 绘制直方图
fig, ax = plt.subplots()
ax.hist(age.dropna(), alpha=0.9, color='blue')

# In[29]:
# 绘制散点图
fig, ax = plt.subplots()
ax.scatter(train['Age'], train['Survived'])

# In[31]:
# 绘制散点图
fig, ax = plt.subplots()
ax.scatter(train['Age'], train['Fare'])

```

[查看详细输出](../Jupyter/数据散布.ipynb)

# 度量数据的相似性和相异性

## 2.1 度量数据的相似性和相异性

### 2.1.1 数据矩阵和相异性矩阵

#### 数据矩阵

**数据矩阵** 或称 **对象-属性结构** ：这种数据结构用关系表的形式或n\*p(n个对象 \* p个属性)矩阵存放 n 个数据对象。

```python
>>> np.random.rand(3,4)
array([[ 0.71077749,  0.04485353,  0.90355374,  0.42123863],
       [ 0.69797357,  0.7439585 ,  0.18741963,  0.08206111],
       [ 0.60488472,  0.06644601,  0.2332587 ,  0.22464888]])
```

#### 相异性矩阵

**相异性矩阵** 或称 **对象 - 对象结构** ：存放 n 个对象两两之间的邻近度，通常用一个 n * n 矩阵表示。

$$\begin{bmatrix} 0 \\ d(2,1) & 0 \\ d(3,1) & d(3,2) & 0 \\ \vdots & \vdots & \vdots \\ d(n,1) & d(n,2) & \ldots & \ldots & 0 \end{bmatrix}$$ 

其中 $d(i,j)$ 是对象 $i$  和对象 $j$ 之间的**相异性**或差别的度量。

### 2.1.2 标称属性的邻近性度量

对于标称属性，两个对象 $i$ 和 $j$ 之间的相异性可以根据不匹配率来计算：

$d(i,j) = \frac{p-m}{p}$

m为匹配的属性数目（即 $i$ 和 $j$ 取值相同状态的属性数），而p是刻画对象的属性总数。

可以通过增加赋予m权重，来调节不同属性的影响。

### 2.1.2 二元属性的邻近性度量

 二元属性的列联表：

| 对象i \ 对象j |  1   |  0   | sum  |
| :-------: | :--: | :--: | :--: |
|     1     |  q   |  r   | q+r  |
|           |  s   |  t   | s+t  |
|    sum    | q+s  | r+t  |  p   |

其中，q 是对象 i 和 j 都取 1 的属性数，r、s、t 类似。

对于对称的两元属性，每个状态都同样重要。基于对称二元属性的相异性称作**对称的二元相异性**，i 和 j 的相异性为：

$d(i, j) = \frac{r+s}{q+r+s+t}$

对于非对称的二元属性，每个状态不同等重要。这样的二元属性经常被认为是“一元的”。对于这种**非对称的二元相异性**，其中负匹配数 t 被认为是不重要的，因此在计算时被忽略：

$d(i,j) = \frac{r+s}{q+r+s}$

互补地，可以基于相似性而不是基于相异性来度量两个二元属性的差别。例如，对象 i 和 j 之间的**非对称的二元相似性** 可以用下式计算：

$sim(i,j) = \frac{q}{q+r+s} = 1 - d(i,j)$

上式的系数 $sim(i,j)$ 被称为 **Jaccard** 系数。

### 2.1.3 数值属性的相异性：闵可夫斯基距离

某些情况下，在计算距离之前数据应该规范化，这涉及变换数据，使之落入较小的公共值域。

#### 欧几里得距离

令 $i = (x_{i1}, x_{i2}, … , x_{ip})$ 和 $j = (x_{j1}, x_{j2}, …, x_{jp})$ 是两个被 p 个数值属性描述的对象。对象 i 和 j 之间的欧几里得距离定义为：

$d(i,j) = \sqrt{(x_{i1} - x_{j1})^2 + (x_{i2} - x_{j2})^2 + \ldots + (x_{ip} - x_{jp})^2}$

#### 曼哈顿（或城市块）距离

定义如下：

$d(i,j) = |x_{i1} - x_{j1}| + |x_{i2} - x_{j2}| + \ldots + |x_{ip} - x_{jp}|$

---

欧几里得距离和曼哈顿距离都满足如下数学性质：

- **非负性：** $ d(i,j) \geqslant 0$ : 距离是一个非负的数值
- **同一性：**$d(i,j) = 0$ : 对象到自身的距离为0
- **对称性：** $d(i,j) = d(j,i)$ : 距离是一个对称函数
- **三角不等式：** $d(i,j)  \leqslant d(i,k) + d(k,j)$ : 从对象 i 到对象 j 的直接距离不会大于途径任何其他对象 k 的距离

满足这些条件的测度称为**度量**。注意非负性被其他三个性质所蕴含。

---

#### 闵可夫斯基距离

**闵可夫斯基距离** 是欧几里得距离和曼哈顿距离的推广，定义如下：

$d(i,j) = \sqrt[h]{|x_{i1} - x_{j1}|^h + |x_{i2} - x_{j2}|^h + \ldots + |x_{ip} - x_{jp}|^h}$

其中，h 是实数，$h \geqslant 1$ 。

#### 上确界距离

**上确界距离** （又称 $L_{max}, L_{\infty}$ 范数 或 **切比雪夫距离**）是 $h \rightarrow \infty$ 时闵可夫斯基距离的推广。为了计算它，我们找出属性 $f$ ，它产生两个对象的最大值差。这个上确界形式化的定义：

$d(i,j) = \lim \limits_{h \rightarrow \infty} (\sum \limits_{f=1}^{p}|x_{if}-x_{jf}|^h)^{\frac{1}{h}} = \max \limits^{p}\limits_{f}|x_{if}-x_{jf}|$

$ L_{\infty}$范数又称为**一致范数**。

### 2.1.4 序数属性的邻近性度量

序数属性的值之间具有意义的序或排位，而相继值之间的量值未知。例如：大、中、小。

假设 $f$ 是用于描述 n 个对象的一组序数属性之一。关于 $f$ 的相异性计算涉及如下步骤：

- 第 $i$ 个对象的 $f$ 值为 $x_{if}$，属性 $f$ 有 $M_f$ 个有序的状态，表示排位 $1, …, M_f$ 。用对应的排位 $r_{if} \in {1, \ldots , M_f}$ 取代 $x_{if}$

- 由于每个序数属性都可以有不同的状态数，所以通常需要将每个属性的值域映射到 $[0.0, 1.0]$ 上，以便每个属性都有相同的权重。我们通过用 $z_{if}$ 代替第 $i$ 个对象的 $r_{if}$ 来实现数据规格化，其中：

  $z_{if} = \frac{r_{if}-1}{M_f-1}$

- 使用 $z_{if}$ 作为第 $i$ 个对象的 $f$ 值

### 2.1.5 混合属性的相异性

- 一种方法是将每种类型的属性分成一组，对每种类型分别进行数据挖掘分析（例如，聚类分析）。

- 一种更可取的方法是将所有属性类型一起处理，只做一次分析。一种这样的技术将不同的属性组合在单个相异性矩阵中，把所有有意义的属性转换到区间 $[0.0, 1.0]$ 上。

  - 假设数据集包含 p 个混合类型属性，对象 $i$ 和 $j$ 之间的相异性 $d(i, j)$ 定义为：

    $d(i,j) = \frac{\sum \limits_{f=1} \limits^{p}\delta^{(f)}_{ij} d^{(f)}_{ij}}{\sum \limits_{f=1} \limits^{p} \delta ^{(f)} _{ij}}$

    其中，指示符 $\delta ^{(f)} _{ij} = 0$ ，如果 $x_{jf}$ 或 $x_{jf}$ 缺失，或者 $x_{if} = x_{jf} = 0$ ，并且 $f$ 是非对称的二元属性；否则，指示符 $\delta ^{(f)} _{if} = 1$ 。属性 $f$ 对 $i$ 和 $j$ 之间相异性的贡献 $d^{(f)}_{ij}$ 根据它的类型计算：

    - $f$ 是数值的：$d^{(f)} _{ij} = \frac{|x_{if} - x_{jf}|}{\max_h x_{hf} - \min_h x_{hf}}$ ，其中 $h$ 遍取属性 $f$ 的所有非缺失对象
    - $f$ 是标称或二元的：如果 $x_{if} = x_{jf}$ ，则 $d^{(f)}_{ij}=0$ ；否则 $d^{(f)}_{ij} = 1$
    - $f$ 是序数的：计算排位 $r_{jf}$ 和 $z_{if} = \frac{r_{if} - 1}{M_f - 1}$ ，并将 $z_{if}$ 作为数值属性对待

  - 上面的步骤与各种单一属性类型的处理相同。唯一的不同是对于数值属性的处理，其中规格化使得变量值映射到了区间 $[0.0, 1.0]$ 。这样，即便描述对象的属性具有不同类型，对象之间的相异性也能够进行计算。

### 2.1.6 余弦相似性

对于稀疏的数值数据，传统的距离度量效果并不好。

**余弦相似性** 是一种度量，它可以用来比较文档，或针对给定的查询词向量对文档排序。令 $\vec{x} $ 和 $\vec{y}$ 是两个待比较的向量，使用余弦度量作为相似性函数，我们有：

$sim(\vec{x},\vec{y}) = \frac{\vec{x} \cdot \vec{y}} {||\vec{x}|| \ ||\vec{y}||}$

其中 $||\vec{x}||$ 是向量 $\vec{x} = (x_1, x_2, x_3, …, x_p)$ 的欧几里得范数，定义为 $\sqrt{x_1^2 + x_2^2 + \ldots + x_p^2}$

当属性是二值属性时，余弦相似性函数可以用共享特征或属性解释。假设如果 $x_i = 1$ 则对象 $\vec{x}$ 具有第 $i$ 个属性。于是，$\vec{x} \cdot \vec{y}$ 是 $\vec{x}$ 和 $\vec{y}$ 共同具有的属性数，而 $|\vec{x}|\ |\vec{y}|$ 是 $|\vec{x}|$ 具有的属性数与$|\vec{y}|$ 具有的属性数的几何平均。于是，$sim(\vec{x},\vec{y})$ 是公共属性相对拥有的一种度量。

对于这种情况，余弦度量的一个简单的变种如下：

$sim(\vec{x},\vec{y}) = \frac{\vec{x} \cdot \vec{y}}{\vec{x} \cdot \vec{x} + \vec{y} \cdot \vec{y} - \vec{x} \cdot \vec{y}}$

这是 $\vec{x}$ 和 $\vec{y}$ 所共有的属性个数与 $\vec{x}$ 或 $\vec{y}$ 所具有的属性个数之间的比率。这个函数被称为 **Tanimoto 系数** 或 **Tanimoto距离** 。