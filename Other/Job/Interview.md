---
title: 机器学习工程师面试
tags:
	- 机器学习
	- 面试
categories:
	- 机器学习
---

# 基础知识

>   统计学习的核心步骤：模型、策略、算法，你应当对logistic、SVM、决策树、KNN及各种聚类方法有深刻的理解。能够随手写出这些算法的核心递归步的伪代码以及他们优化的函数表达式和对偶问题形式。
>
>   算法的目标函数和优化方法

## 算法

### LR



### 朴素贝叶斯

### LDA

### PCA

### 随机森林

>   随机森林怎么取最后的结果？ 
>
>     答：对于分类任务，随机森林是多数表决； 
>
>     对于回归任务，随机森林是简单平均 
>
>   随机森林是怎样避免ID3算法信息增益的缺点的？ 
>
>     答：首先说下信息增益的过程，决策树算法本质上就是要找出每一列的最佳划分以及不同列划分的先后顺序及排布。信息增益的缺点是比较偏向选择取值多的属性。而gini系数每次都是二分，所以跟属性多少没有关系。

### GDBT

-   利用损失函数的负梯度在当前模型的值作为回归问题提升树算法中的残差的近似值，拟合一个回归树

### SVM

#### 原理

#### 核

#### 问题

##### 怎样去优化SVM算法模型

-   SMO
-   KKT条件
-   凸二次规划

### 决策树

### 聚类

#### KNN

### RNN

## 优化算法

### 梯度下降

### 坐标下降法

### 牛顿迭代法

>   对比了下梯度下降法只是泰勒的一阶展开式，而牛顿法是泰勒的二阶展开式，牛顿法主要问题在于海森矩阵求逆是一个很复杂的过程，所有才会有拟牛顿法以及相应的改进算法。

### 参考

-   [参考一](http://blog.csdn.net/zkq_1986/article/details/52317258)

## 最优化

### 拉格朗日乘子法

### KKT

# 常见问题

## Boost算法

## CART

回归树用平方误差最小化准则，分类树用基尼指数最小化准则

## 基尼指数

## 随机森林和GDBT比较

>   GBDT和随机森林的相同点： 
>
>     1、都是由多棵树组成 
>
>     2、最终的结果都是由多棵树一起决定 
>
>     GBDT和随机森林的不同点： 
>
>     1、组成随机森林的树可以是分类树，也可以是回归树；而GBDT只由回归树组成 
>
>     2、组成随机森林的树可以并行生成；而GBDT只能是串行生成 
>
>     3、对于最终的输出结果而言，随机森林采用多数投票等；而GBDT则是将所有结果累加起来，或者加权累加起来 
>
>     4、随机森林对异常值不敏感，GBDT对异常值非常敏感 
>
>     5、随机森林对训练集一视同仁，GBDT是基于权值的弱分类器的集成 
>
>     6、随机森林是通过减少模型方差提高性能，GBDT是通过减少模型偏差提高性能

## 朴素贝叶斯与逻辑回归区别

## Sigmoid函数

## 为什么损失函数有个负号

这是因为要应用梯度下降法，引入的。不加负号也可以，梯度上升法。这都是一样的。

## LR和SVM有什么不同

-   SVM决策面只由少量的支持向量决定，而LR的话是所有样本都会参与决策面的更新。
-   SVM对于异常点不敏感，而LR敏感。SVM更加健壮，决策面不受非支持向量影响。

## 对偶问题

### 为什么把原问题转为对偶问题

-   因为原问题是凸二次规划问题，转换为对偶问题更加高效

### SVM原问题与对偶问题关系

### 为什么求解对偶问题更加有效

-   因为只用求解alpha系数，而alpha系数只有支持向量才非0，其他全部为0

## ID3、C4.5对比

## 过拟合问题

### 各个算法如何防止过拟合

>   剪枝、正则（L1，L2）

#### 正则化

##### L1正则L2正则

##### L1 与 L2 的区别以及如何解决 L1 求导困难

##### 为什么L1正则可以实现参数稀疏，而L2正则不可以

-   L1正则因为是绝对值形式，很多系数被压缩为0,。而L2正则是很多系数被压迫到接近于0，而不是0

##### 为什么L1很多系数可以被压缩为0，L2是被压缩至接近于0

-   图像上，L1正则是正方形，L2正则是圆形
-   L1正则的往往取到正方形顶点，即有很多参数为0
-   L2正则往往去不到圆形和参数线的交点，即很多分量被压缩到接近于0

# Spark

>   Spark是多线程模式，怎么退化为多进程模式。
>
>   在每个executor core设置为1，即每个executor是单线程的。

>   spark原理
>
>   spark Executor memory 给16G  executor core 给2个。问每个core分配多少内存

## 原理

# 基础知识

## 操作系统

### 进程和线程

### 线程安全

## 数据库

### inner join 和outer join的区别

# 概念

## 数学

### 最大似然估计

最大似然估计就是求让已知事件发生的概率最大的参数。

### 置信度

## 算法

### 全排列

### 树的遍历

>   给定二叉树前序、中序遍历结果。求后序遍历结果

### 快排

## Python

### Python如何定义一个私有变量

# 参考

-   [参考一](https://www.zhihu.com/question/23259302/answer/24857674)