{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conv2d 示例\n",
    "\n",
    "## 参考\n",
    " - [参考一](https://www.cnblogs.com/qggg/p/6832342.html)\n",
    " \n",
    "## 示例\n",
    "- 一张3×3单通道的图像（对应的shape：[1，3，3，1]），用一个1×1的卷积核（对应的shape：[1，1，1，1]）去做卷积，最后会得到一张3×3的feature map。\n",
    "\n",
    "- 增加图片的通道数，使用一张3×3五通道的图像（对应的shape：[1，3，3，5]），用一个1×1的卷积核（对应的shape：[1，1，1，1]）去做卷积，仍然是一张3×3的feature map，这就相当于每一个像素点，卷积核都与该像素点的每一个通道做卷积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "input = tf.Variable(tf.random_normal([1, 3, 3, 5]))\n",
    "filter = tf.Variable(tf.random_normal([1, 1, 5, 1]))\n",
    "\n",
    "op = tf.nn.conv2d(input, filter, strides=[1, 1, 1, 1], padding='VALID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 把卷积核扩大，现在用3×3的卷积核做卷积，最后的输出是一个值，相当于情况2的feature map所有像素点的值求和。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tf.Variable(tf.random_normal([1, 3, 3, 5]))\n",
    "filter = tf.Variable(tf.random_normal([3, 3, 5, 1]))\n",
    "\n",
    "op = tf.nn.conv2d(input, filter, strides=[1, 1, 1, 1], padding='VALID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 图片扩大到5×5，仍然是3×3的卷积核，令步长为1，输出3×3的feature map。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tf.Variable(tf.random_normal([1, 5, 5, 5]))\n",
    "filter = tf.Variable(tf.random_normal([3, 3, 5, 1]))\n",
    "\n",
    "op = tf.nn.conv2d(input, filter, strides=[1, 1, 1, 1], padding='VALID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积核以步长1滑动遍历全图，以下x所在的位置，表示卷积核停留的位置，每停留一个，输出feature map的一个像素。\n",
    "\n",
    "```python\n",
    ".....\n",
    ".xxx.\n",
    ".xxx.\n",
    ".xxx.\n",
    ".....\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参数padding的值为‘SAME’时，表示卷积核可以停留在图像边缘。\n",
    "\n",
    "此时，卷积核以步长1滑动遍历全图，以下x所在的位置，表示卷积核停留的位置，每停留一个，输出feature map的一个像素。\n",
    "\n",
    "```python\n",
    "xxxxx\n",
    "xxxxx\n",
    "xxxxx\n",
    "xxxxx\n",
    "```\n",
    "\n",
    "输出5×5的feature map。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tf.Variable(tf.random_normal([1,5,5,5]))\n",
    "filter = tf.Variable(tf.random_normal([3,3,5,1]))\n",
    "\n",
    "op = tf.nn.conv2d(input, filter, strides=[1, 1, 1, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 当有多个卷积核时"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tf.Variable(tf.random_normal([1, 3, 3, 5]))\n",
    "filter = tf.Variable(tf.random_normal([3, 3, 5, 7]))\n",
    "\n",
    "op = tf.nn.conv2d(input, filter, strides=[1, 1, 1, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此时输出7张5×5的feature map。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 步长不为一时，对于图片，因为只有两维，通常`strides`取`[1，stride，stride，1]`。`stride`为步长。\n",
    "\n",
    "    取步长为2，则卷积核停留位置如下:\n",
    "    ```python\n",
    "x.x.x\n",
    "x.x.x\n",
    "x.x.x\n",
    "x.x.x\n",
    "x.x.x\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tf.Variable(tf.random_normal([1, 5, 5, 5]))\n",
    "filter = tf.Variable(tf.random_normal([3, 3, 5, 7]))\n",
    "\n",
    "op = tf.nn.conv2d(input, filter, strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- batch为输入图片数量，当为10时"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tf.Variable(tf.random_normal([10,5,5,5]))\n",
    "filter = tf.Variable(tf.random_normal([3,3,5,7]))\n",
    "\n",
    "op = tf.nn.conv2d(input, filter, strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- case 2 ---------\n",
      "<class 'numpy.ndarray'>\n",
      "[[[[ 5.]\n",
      "   [ 5.]\n",
      "   [ 5.]]\n",
      "\n",
      "  [[ 5.]\n",
      "   [ 5.]\n",
      "   [ 5.]]\n",
      "\n",
      "  [[ 5.]\n",
      "   [ 5.]\n",
      "   [ 5.]]]]\n",
      "-------------------------\n",
      "\n",
      "\n",
      "---------- case 3 ---------\n",
      "<class 'numpy.ndarray'>\n",
      "[[[[ 45.]]]]\n",
      "-------------------------\n",
      "\n",
      "\n",
      "---------- case 4 ---------\n",
      "<class 'numpy.ndarray'>\n",
      "[[[[ 45.]\n",
      "   [ 45.]\n",
      "   [ 45.]]\n",
      "\n",
      "  [[ 45.]\n",
      "   [ 45.]\n",
      "   [ 45.]]\n",
      "\n",
      "  [[ 45.]\n",
      "   [ 45.]\n",
      "   [ 45.]]]]\n",
      "-------------------------\n",
      "\n",
      "\n",
      "---------- case 5 ---------\n",
      "<class 'numpy.ndarray'>\n",
      "[[[[ 20.]\n",
      "   [ 30.]\n",
      "   [ 30.]\n",
      "   [ 30.]\n",
      "   [ 20.]]\n",
      "\n",
      "  [[ 30.]\n",
      "   [ 45.]\n",
      "   [ 45.]\n",
      "   [ 45.]\n",
      "   [ 30.]]\n",
      "\n",
      "  [[ 30.]\n",
      "   [ 45.]\n",
      "   [ 45.]\n",
      "   [ 45.]\n",
      "   [ 30.]]\n",
      "\n",
      "  [[ 30.]\n",
      "   [ 45.]\n",
      "   [ 45.]\n",
      "   [ 45.]\n",
      "   [ 30.]]\n",
      "\n",
      "  [[ 20.]\n",
      "   [ 30.]\n",
      "   [ 30.]\n",
      "   [ 30.]\n",
      "   [ 20.]]]]\n",
      "-------------------------\n",
      "\n",
      "\n",
      "---------- case 6 ---------\n",
      "<class 'numpy.ndarray'>\n",
      "[[[[ 20.  20.  20.  20.  20.  20.  20.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 20.  20.  20.  20.  20.  20.  20.]]\n",
      "\n",
      "  [[ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 45.  45.  45.  45.  45.  45.  45.]\n",
      "   [ 45.  45.  45.  45.  45.  45.  45.]\n",
      "   [ 45.  45.  45.  45.  45.  45.  45.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]]\n",
      "\n",
      "  [[ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 45.  45.  45.  45.  45.  45.  45.]\n",
      "   [ 45.  45.  45.  45.  45.  45.  45.]\n",
      "   [ 45.  45.  45.  45.  45.  45.  45.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]]\n",
      "\n",
      "  [[ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 45.  45.  45.  45.  45.  45.  45.]\n",
      "   [ 45.  45.  45.  45.  45.  45.  45.]\n",
      "   [ 45.  45.  45.  45.  45.  45.  45.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]]\n",
      "\n",
      "  [[ 20.  20.  20.  20.  20.  20.  20.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 20.  20.  20.  20.  20.  20.  20.]]]]\n",
      "-------------------------\n",
      "\n",
      "\n",
      "---------- case 7 ---------\n",
      "<class 'numpy.ndarray'>\n",
      "[[[[ 20.  20.  20.  20.  20.  20.  20.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 20.  20.  20.  20.  20.  20.  20.]]\n",
      "\n",
      "  [[ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 45.  45.  45.  45.  45.  45.  45.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]]\n",
      "\n",
      "  [[ 20.  20.  20.  20.  20.  20.  20.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 20.  20.  20.  20.  20.  20.  20.]]]]\n",
      "-------------------------\n",
      "\n",
      "\n",
      "---------- case 8 ---------\n",
      "<class 'numpy.ndarray'>\n",
      "[[[[ 20.  20.  20.  20.  20.  20.  20.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 20.  20.  20.  20.  20.  20.  20.]]\n",
      "\n",
      "  [[ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 45.  45.  45.  45.  45.  45.  45.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]]\n",
      "\n",
      "  [[ 20.  20.  20.  20.  20.  20.  20.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 20.  20.  20.  20.  20.  20.  20.]]]\n",
      "\n",
      "\n",
      " [[[ 20.  20.  20.  20.  20.  20.  20.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 20.  20.  20.  20.  20.  20.  20.]]\n",
      "\n",
      "  [[ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 45.  45.  45.  45.  45.  45.  45.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]]\n",
      "\n",
      "  [[ 20.  20.  20.  20.  20.  20.  20.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 20.  20.  20.  20.  20.  20.  20.]]]\n",
      "\n",
      "\n",
      " [[[ 20.  20.  20.  20.  20.  20.  20.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 20.  20.  20.  20.  20.  20.  20.]]\n",
      "\n",
      "  [[ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 45.  45.  45.  45.  45.  45.  45.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]]\n",
      "\n",
      "  [[ 20.  20.  20.  20.  20.  20.  20.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 20.  20.  20.  20.  20.  20.  20.]]]\n",
      "\n",
      "\n",
      " [[[ 20.  20.  20.  20.  20.  20.  20.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 20.  20.  20.  20.  20.  20.  20.]]\n",
      "\n",
      "  [[ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 45.  45.  45.  45.  45.  45.  45.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]]\n",
      "\n",
      "  [[ 20.  20.  20.  20.  20.  20.  20.]\n",
      "   [ 30.  30.  30.  30.  30.  30.  30.]\n",
      "   [ 20.  20.  20.  20.  20.  20.  20.]]]]\n",
      "-------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oplist=[]\n",
    "# [batch, in_height, in_width, in_channels]\n",
    "input_arg  = tf.Variable(tf.ones([1, 3, 3, 5]))\n",
    "# [filter_height, filter_width, in_channels, out_channels]\n",
    "filter_arg = tf.Variable(tf.ones([1 ,1 , 5 ,1]))\n",
    "\n",
    "op2 = tf.nn.conv2d(input_arg, filter_arg, strides=[1,1,1,1], use_cudnn_on_gpu=False, padding='VALID')\n",
    "oplist.append([op2, \"case 2\"])\n",
    "\n",
    "# [batch, in_height, in_width, in_channels]\n",
    "input_arg  = tf.Variable(tf.ones([1, 3, 3, 5]))\n",
    "# [filter_height, filter_width, in_channels, out_channels]\n",
    "filter_arg = tf.Variable(tf.ones([3 ,3 , 5 ,1]))\n",
    "\n",
    "op2 = tf.nn.conv2d(input_arg, filter_arg, strides=[1,1,1,1], use_cudnn_on_gpu=False, padding='VALID')\n",
    "oplist.append([op2, \"case 3\"])\n",
    "\n",
    "# [batch, in_height, in_width, in_channels]\n",
    "input_arg  = tf.Variable(tf.ones([1, 5, 5, 5]))\n",
    "# [filter_height, filter_width, in_channels, out_channels]\n",
    "filter_arg = tf.Variable(tf.ones([3 ,3 , 5 ,1]))\n",
    "\n",
    "op2 = tf.nn.conv2d(input_arg, filter_arg, strides=[1,1,1,1], use_cudnn_on_gpu=False, padding='VALID')\n",
    "oplist.append([op2, \"case 4\"])\n",
    "\n",
    "# [batch, in_height, in_width, in_channels]\n",
    "input_arg  = tf.Variable(tf.ones([1, 5, 5, 5]))\n",
    "# [filter_height, filter_width, in_channels, out_channels]\n",
    "filter_arg = tf.Variable(tf.ones([3 ,3 , 5 ,1]))\n",
    "op2 = tf.nn.conv2d(input_arg, filter_arg, strides=[1,1,1,1], use_cudnn_on_gpu=False, padding='SAME')\n",
    "oplist.append([op2, \"case 5\"])\n",
    "\n",
    "# [batch, in_height, in_width, in_channels]\n",
    "input_arg  = tf.Variable(tf.ones([1, 5, 5, 5]))\n",
    "# [filter_height, filter_width, in_channels, out_channels]\n",
    "filter_arg = tf.Variable(tf.ones([3 ,3 , 5 ,7]))\n",
    "op2 = tf.nn.conv2d(input_arg, filter_arg, strides=[1,1,1,1], use_cudnn_on_gpu=False, padding='SAME')\n",
    "oplist.append([op2, \"case 6\"])\n",
    "\n",
    "\n",
    "# [batch, in_height, in_width, in_channels]\n",
    "input_arg  = tf.Variable(tf.ones([1, 5, 5, 5]))\n",
    "# [filter_height, filter_width, in_channels, out_channels]\n",
    "filter_arg = tf.Variable(tf.ones([3 ,3 , 5 ,7]))\n",
    "op2 = tf.nn.conv2d(input_arg, filter_arg, strides=[1,2,2,1], use_cudnn_on_gpu=False, padding='SAME')\n",
    "oplist.append([op2, \"case 7\"])\n",
    "\n",
    "\n",
    "# [batch, in_height, in_width, in_channels]\n",
    "input_arg  = tf.Variable(tf.ones([4, 5, 5, 5]))\n",
    "# [filter_height, filter_width, in_channels, out_channels]\n",
    "filter_arg = tf.Variable(tf.ones([3 ,3 , 5 ,7]))\n",
    "op2 = tf.nn.conv2d(input_arg, filter_arg, strides=[1,2,2,1], use_cudnn_on_gpu=False, padding='SAME')\n",
    "oplist.append([op2, \"case 8\"])\n",
    "\n",
    "with tf.Session() as a_sess:\n",
    "    a_sess.run(tf.global_variables_initializer())\n",
    "    for aop in oplist:\n",
    "        print(\"---------- {} ---------\".format(aop[1]))\n",
    "        res = a_sess.run(aop[0])\n",
    "        print('type :', type(res))\n",
    "        print('shape:', res.shape)\n",
    "        print('value:\\n', res)\n",
    "        print('-------------------------\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
