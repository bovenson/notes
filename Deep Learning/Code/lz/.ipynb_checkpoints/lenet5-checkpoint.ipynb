{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********  Train Set  **********\n",
      "Count       :  30000\n",
      "Images Shape:  (30000, 900)\n",
      "Labels Shape:  (30000,)\n",
      "\n",
      "**********  Validate Set  **********\n",
      "Count       :  30000\n",
      "Images Shape:  (30000, 900)\n",
      "Labels Shape:  (30000,)\n"
     ]
    }
   ],
   "source": [
    "from data_generator import *\n",
    "data_set = generate_data(recreate=False)\n",
    "\n",
    "# Transform\n",
    "data_set.train.trans()\n",
    "data_set.validation.trans()\n",
    "\n",
    "train_data = data_set.train\n",
    "validate_data = data_set.validation\n",
    "X_train, y_train = data_set.train.images, data_set.train.labels\n",
    "X_train = X_train.reshape([len(X_train), 30, 30, 1])\n",
    "X_validate, y_validate = data_set.validation.images, data_set.validation.labels\n",
    "X_validate = X_validate.reshape([len(X_validate), 30, 30, 1])\n",
    "print('*' * 10, ' Train Set ', '*' * 10)\n",
    "print('Count       : ', train_data.num_examples)\n",
    "print('Images Shape: ', train_data.images.shape)\n",
    "print('Labels Shape: ', train_data.labels.shape)\n",
    "print()\n",
    "\n",
    "print('*' * 10, ' Validate Set ', '*' * 10)\n",
    "print('Count       : ', validate_data.num_examples)\n",
    "print('Images Shape: ', validate_data.images.shape)\n",
    "print('Labels Shape: ', validate_data.labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 显示图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAA9JJREFUeJztnEFoHGUYhp/XWk8GrHhZtKiI5OKhssGLh5wE8VK9FHsQhcLmUqg3xZPHHqxXyYqFHgoiKNibeEjiTbopRW1LtYjallIRBaMXaX097KSspbuZ3Zl82Z18D4TJ/Pnnn48nf76dmXzzyzZJDPftdAC7iZQdSMoOJGUHkrIDSdmBpOxAKsmW9KKky5KuSHq7rqCaiia9qZG0B/geeAG4BpwFDtu+WF94zeL+Csc+B1yx/SOApI+Bg8BQ2ZIae7tqW1v1qZJGHgWuDuxfK9r+h6SOpJ6kXoVzNYIqM7sUtrtAF5o9s8tQZWZfB/YP7D9WtCVDqCL7LPC0pCclPQC8CpypJ6xmMnEasX1L0lHgC2APcNL2hdoiayATX/pNdLIG5+ztvhpJxiRlB5KyA0nZgaTsQFJ2ICk7kJQdSMoOJGUHkrIDSdmBpOxAUnYgKTuQlB1Iyg4kZQeSsgNJ2YFse5HOIK1Wi06nE3nKELrdbql+ObMDyVKGmshShikjNGdXYWVlZadDGMrS0lKpfjmzAwnN2fPz815eXi7Vd3V1deT+IGtraxWiqodacrak/ZJWJF2UdEHSsaL9YUlfSvqh2O6rI+gms+XMltQCWrbPSZoD1oGXgTeA320fL15e2mf7rVFjzc3Nud1ulwpsnNm6uLhYuu92sL6+zsbGRvWZbfuG7XPF9xvAJfqvcxwEThXdTtH/BSQjGCtnS3oC+Ap4BvjF9kNFu4A/NvdHHL+rr7NLX/pJehD4FHjT9p99v3dO5GEiJXWAxt2jD07ShYWFUseUuvSTtJe+6NO2Pyuabxb5fDOv/zokqK7tBdvlImowW87sIkV8BFyy/f7Aj84ArwPHi+3nW43Vbrfp9Zrxht7gX3ZZyqSR54HXgG8lnS/a3qEv+RNJR4CfgUNjn32XkQ+iaiIfRE0ZKTuQlB1Iyg4kZQeSsgNJ2YGk7EBSdiApO5CUHUjKDiS6buQ34O9iO0s8wuiYHy8zSOhTPwBJvVn7R0JdMWcaCSRlB7ITsssVM08XtcQcnrN3M5lGAgmTPQtrbY+oa3xX0nVJ54uvlyYaPyKNzMpa2yPqGg8Bf9l+r8r4UTP7zlrbtv8BNtfanipG1DXWQpTsUmttTxNFXeOzwNdF01FJ30g6OWl5dH5A3oO76xqBD4CngAPADeDEJONGyZ6ZtbbvVddo+6bt27b/BT6knxbHJkr2TKy1PayucbOAtOAV4LtJxg956jdDa20Pq2s8LOkAYOAnoNzrYXeRd5CB5AdkICk7kJQdSMoOJGUHkrIDSdmBpOxA/gPeLE2Ghwha4QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108e40a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "img = X_train[0].reshape([30, 30])\n",
    "\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输入\n",
    "LeNet接受`32*32*color_channels`作为输入。\n",
    "\n",
    "# 结构\n",
    "- 第一层\n",
    "    - 卷积层: \n",
    "        - 卷积核尺寸: 3\n",
    "        - 深度     : 6\n",
    "        - 步长     : 1\n",
    "        - 全零填充\n",
    "        - 输出     : `30*30*6`\n",
    "    - 激活函数: ReLu\n",
    "    - 池化层: \n",
    "        - 过滤器尺寸: 2\n",
    "        - 步长     : 2\n",
    "        - 输出     : `15*15*6`\n",
    "- 第二层\n",
    "    - 卷积层\n",
    "        - 输入     : `15*15*6`\n",
    "        - 深度     : 16\n",
    "        - 步长     : 1\n",
    "        - 卷积核尺寸: 3\n",
    "        - 输出     : `15*15*16`\n",
    "    - 激活函数: ReLu\n",
    "    - 池化层: \n",
    "        - 过滤器尺寸: 3\n",
    "        - 步长     : 3\n",
    "        - 输出     : `5*5*16`\n",
    "    - Flatten: Flatten the output shape of the final pooling layer such that it's 1D instead of 3D\n",
    "- 第三层\n",
    "    - 全连接层: 120个神经元\n",
    "    - 激活函数: ReLu\n",
    "- 第四层\n",
    "    - 全连接层: 84个神经元\n",
    "    - 激活函数: ReLu\n",
    "- 第五层\n",
    "    - 全连接层(Logits): 50个神经元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "def conv2d(x, W, b, stride=1, padding='SAME'):\n",
    "    \"\"\"\n",
    "    实现纳卷积操作\n",
    "    x: 输入\n",
    "    W: 卷积核\n",
    "    b: 偏置\n",
    "    strides: 步长\n",
    "    padding: padding\n",
    "    \"\"\"\n",
    "    x = tf.nn.conv2d(input=x, filter=W, strides=[1, stride, stride, 1], padding=padding)\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def maxpool2d(x, k=2, padding='SAME'):\n",
    "    \"\"\"\n",
    "    池化操作\n",
    "    x: 输入\n",
    "    k: 步长及过滤器尺寸\n",
    "    padding: padding\n",
    "    \"\"\"\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding=padding)\n",
    "\n",
    "\n",
    "def fc_relu(x, W, b):\n",
    "    \"\"\"\n",
    "    全连接层激活函数\n",
    "    x: 输入\n",
    "    W: 卷积核\n",
    "    b: 偏置\n",
    "    \"\"\"\n",
    "    x = tf.add(tf.matmul(x, W), b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def LeNet(x):\n",
    "    \"\"\"定义LeNet\"\"\"\n",
    "    # 定义参数\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    weights = {\n",
    "        # 第一层; 卷积操作卷积核\n",
    "        'wc1': tf.Variable(tf.truncated_normal(shape=(3, 3, 1, 6), mean = mu, stddev = sigma)), \n",
    "        # 第三层; 卷积操作卷积核\n",
    "        'wc2': tf.Variable(tf.truncated_normal(shape=(3, 3, 6, 16), mean = mu, stddev = sigma)), \n",
    "        # 第五层; 全连接操作\n",
    "        'wfc': tf.Variable(tf.truncated_normal(shape=(5*5*16, 120), mean = mu, stddev = sigma)), \n",
    "        # 输出层; 全连接操作\n",
    "        'out': tf.Variable(tf.truncated_normal(shape=(120, 50), mean = mu, stddev = sigma)),\n",
    "    }\n",
    "    biases = {\n",
    "        # 第一层\n",
    "        'bc1': tf.Variable(tf.zeros(6)),\n",
    "        # 第三层\n",
    "        'bc2': tf.Variable(tf.zeros(16)),\n",
    "        # 第五层\n",
    "        'bfc': tf.Variable(tf.zeros(120)),\n",
    "        # 输出层\n",
    "        'out': tf.Variable(tf.zeros(50))\n",
    "    }\n",
    "    \n",
    "    # 第一层\n",
    "    ## 卷积操作\n",
    "    ### 输入 = 30*30*1\n",
    "    ### 输出 = 30*30*6\n",
    "    ## 激活操作\n",
    "    ## 池化操作\n",
    "    ### 输入 = 30*30*6\n",
    "    ### 输出 = 15*15*6\n",
    "    c1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    c1 = maxpool2d(c1, k=2)\n",
    "    \n",
    "    # 第二层\n",
    "    ## 卷积操作\n",
    "    ### 输入 = 15*15*6\n",
    "    ### 输出 = 15*15*16\n",
    "    ## 激活操作\n",
    "    ## 池化操作\n",
    "    ### 输入 = 15*15*6\n",
    "    ### 输出 = 5*5*6\n",
    "    c2 = conv2d(c1, weights['wc2'], biases['bc2'])\n",
    "    c2 = maxpool2d(c2, k=3)\n",
    "    \n",
    "    # Flatten\n",
    "    ## input 5*5*16\n",
    "    ## output 400\n",
    "    c2_flat = flatten(c2)\n",
    "    \n",
    "    # 第三层\n",
    "    ## Fully Connected\n",
    "    ## Input = 400\n",
    "    ## Output = 120\n",
    "    # Activation\n",
    "    fc = fc_relu(c2_flat, weights['wfc'], biases['bfc']) \n",
    "    \n",
    "    # Layer 第五层\n",
    "    ## 输出层\n",
    "    ## Fully Connected\n",
    "    ## Input = 120\n",
    "    ## Output = 50\n",
    "    logits = tf.add(tf.matmul(fc, weights['out']), biases['out'])\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征和标签\n",
    "- x is a placeholder for a batch of input images\n",
    "- y is a placeholder for a batch of output labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 30, 30, 1), name='x-input')\n",
    "y = tf.placeholder(tf.int32, (None), name='y-input')\n",
    "one_hot_y = tf.one_hot(y, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-acb6c96dcd18>:4: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rate = 0.001\n",
    "\n",
    "logits = LeNet(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=one_hot_y)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "EPOCHS 0 ...\n",
      "Validation Accuracy = 0.657\n",
      "\n",
      "EPOCHS 1 ...\n",
      "Validation Accuracy = 0.510\n",
      "\n",
      "EPOCHS 2 ...\n",
      "Validation Accuracy = 0.479\n",
      "\n",
      "EPOCHS 3 ...\n",
      "Validation Accuracy = 0.329\n",
      "\n",
      "EPOCHS 4 ...\n",
      "Validation Accuracy = 0.260\n",
      "\n",
      "EPOCHS 5 ...\n",
      "Validation Accuracy = 0.322\n",
      "\n",
      "EPOCHS 6 ...\n",
      "Validation Accuracy = 0.358\n",
      "\n",
      "EPOCHS 7 ...\n",
      "Validation Accuracy = 0.329\n",
      "\n",
      "EPOCHS 8 ...\n",
      "Validation Accuracy = 0.312\n",
      "\n",
      "EPOCHS 9 ...\n",
      "Validation Accuracy = 0.289\n",
      "\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter('log', sess.graph)\n",
    "    num_examples = train_data.num_examples\n",
    "    \n",
    "    print('Training...\\n')\n",
    "    \n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            # print(batch_x.shape)\n",
    "            # print(batch_y.shape)\n",
    "            # batch_x = batch_x.reshape([len(batch_x), 30, 30, 1])\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        \n",
    "        validation_accuracy = evaluate(X_validate, y_validate)\n",
    "        print('EPOCHS {} ...'.format(i))\n",
    "        print('Validation Accuracy = {:.3f}'.format(validation_accuracy))\n",
    "        print()\n",
    "        \n",
    "    saver.save(sess, './model')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
